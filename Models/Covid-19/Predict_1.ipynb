{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79e5f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import yaml\n",
    "\n",
    "import yaml\n",
    "import numpy as np   # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets,models\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "import time\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "# Get configs from config file\n",
    "stream = open(\"config.yaml\", 'r')\n",
    "config_dict = yaml.safe_load(stream)\n",
    "batch_size = config_dict['batch_size']\n",
    "learning_rate = config_dict['lr']\n",
    "model_pth = config_dict['model_pth']\n",
    "train_data = config_dict['train_data']\n",
    "valid_data = config_dict['valid_data']\n",
    "test_data = config_dict['test_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e462e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((230, 230)),\n",
    "        transforms.RandomRotation(30,),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize((400, 400)),\n",
    "        transforms.CenterCrop((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7738ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2266c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for loading test dataset\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.path\n",
    "        image = pil_loader(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f1f92b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_class(indices):\n",
    "    indices = indices[0]\n",
    "    classes  = []\n",
    "    for index in indices:\n",
    "        \n",
    "        if index==0:\n",
    "            classes.append('Covid Positive')\n",
    "        else:\n",
    "            classes.append(\"Covid Negative\")\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d10fe3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_path, dataloader, print_progress=False):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    :param model_path: Path of Model used for prediction\n",
    "    :param dataloader: Test DataLoader\n",
    "    :param print_progress: Prints progress if True\n",
    "    :return: Prediction(as a list) on test folder defined by config file\n",
    "    \"\"\"\n",
    "\n",
    "    model = torch.load(model_path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = {}\n",
    "    with torch.no_grad():\n",
    "        for ii, (images,_) in enumerate(dataloader, start=1):\n",
    "\n",
    "            if print_progress:\n",
    "                if ii % 5 == 0:\n",
    "                    print('Batch {}/{}'.format(ii, len(dataloader)))\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            logps = model(images)\n",
    "            ps = torch.exp(logps)\n",
    "\n",
    "            # Top indices\n",
    "            _, top_indices = ps.topk(1)\n",
    "            top_indices = top_indices.detach().cpu().numpy().tolist()\n",
    "            #print(top_indices)\n",
    "            # Convert indices to classes\n",
    "            top_classes = idx_to_class(top_indices)\n",
    "            # print(\"Img:\" ,img_names)\n",
    "            #for i, img_name in enumerate(img_names):\n",
    "                #predictions[img_name] = top_classes[i]\n",
    "\n",
    "        #print('\\nPrediction Generation Completed')\n",
    "\n",
    "    return top_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b90f0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = data_dir + os.path.join(model_pth,'DenseNet_13.24_2022-05-07.pth')\n",
    "test_dataset = TestDataset(\"./train/covid/4-x-day1.jpg\",data_transforms['test'])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "pre = predict(model_path,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "298380e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Covid Positive']\n"
     ]
    }
   ],
   "source": [
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    model_pth : path of model\n",
    "    img_path : image path\n",
    "    pre: stores predictions\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
